{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h2>CS 4780/5780 Final Project: </h2>\n",
        "<h3>Election Result Prediction for US Counties</h3>\n",
        "\n",
        "Names and NetIDs for your group members: coa22 and mia27"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Introduction:</h3>\n",
        "\n",
        "<p> The final project is about conducting a real-world machine learning project on your own, with everything that is involved. Unlike in the programming projects 1-5, where we gave you all the scaffolding and you just filled in the blanks, you now start from scratch. The programming project provide templates for how to do this, and the most recent video lectures summarize some of the tricks you will need (e.g. feature normalization, feature construction). So, this final project brings realism to how you will use machine learning in the real world.  </p>\n",
        "\n",
        "The task you will work on is forecasting election results. Economic and sociological factors have been widely used when making predictions on the voting results of US elections. Economic and sociological factors vary a lot among counties in the United States. In addition, as you may observe from the election map of recent elections, neighbor counties show similar patterns in terms of the voting results. In this project you will bring the power of machine learning to make predictions for the county-level election results using Economic and sociological factors and the geographic structure of US counties. </p>\n",
        "<p>\n",
        "\n",
        "<h3>Your Task:</h3>\n",
        "Plase read the project description PDF file carefully and make sure you write your code and answers to all the questions in this Jupyter Notebook. Your answers to the questions are a large portion of your grade for this final project. Please import the packages in this notebook and cite any references you used as mentioned in the project description. You need to print this entire Jupyter Notebook as a PDF file and submit to Gradescope and also submit the ipynb runnable version to Canvas for us to run.\n",
        "\n",
        "<h3>Due Date:</h3>\n",
        "The final project dataset and template jupyter notebook will be due on <strong>December 15th</strong> . Note that <strong>no late submissions will be accepted</strong>  and you cannot use any of your unused slip days before.\n",
        "</p>"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "![colored_graph](colored_graph.png)\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>1.1 Import:</h3><p>\n",
        "Please import necessary packages to use. Note that learning and using packages are recommended but not required for this project. Some official tutorial for suggested packacges includes:\n",
        "    \n",
        "https://scikit-learn.org/stable/tutorial/basic/tutorial.html\n",
        "    \n",
        "https://pytorch.org/tutorials/\n",
        "    \n",
        "https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html\n",
        "<p>"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Base Imports\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn as sk"
      ],
      "execution_count": 4,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>1.2 Weighted Accuracy:</h3><p>\n",
        "Since our dataset labels are heavily biased, you need to use the following function to compute weighted accuracy throughout your training and validation process and we use this for testing on Kaggle.\n",
        "<p>"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def weighted_accuracy(true, pred):\n",
        "    assert(len(pred) == len(true))\n",
        "    num_labels = len(true)\n",
        "    num_pos = sum(true)\n",
        "    num_neg = num_labels - num_pos\n",
        "    frac_pos = num_pos/num_labels\n",
        "    weight_pos = 1/frac_pos\n",
        "    weight_neg = 1/(1-frac_pos)\n",
        "    num_pos_correct = 0\n",
        "    num_neg_correct = 0\n",
        "    for pred_i, true_i in zip(pred, true):\n",
        "        num_pos_correct += (pred_i == true_i and true_i == 1)\n",
        "        num_neg_correct += (pred_i == true_i and true_i == 0)\n",
        "    weighted_accuracy = ((weight_pos * num_pos_correct) \n",
        "                         + (weight_neg * num_neg_correct))/((weight_pos * num_pos) + (weight_neg * num_neg))\n",
        "    return weighted_accuracy"
      ],
      "execution_count": 12,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Part 2: Baseline Solution</h2><p>\n",
        "Note that your code should be commented well and in part 2.4 you can refer to your comments. (e.g. # Here is SVM, \n",
        "# Here is validation for SVM, etc). Also, we recommend that you do not to use 2012 dataset and the graph dataset to reach the baseline accuracy for 68% in this part, a basic solution with only 2016 dataset and reasonable model selection will be enough, it will be great if you explore thee graph and possibly 2012 dataset in Part 3."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>2.1 Preprocessing and Feature Extraction:</h3><p>\n",
        "Given the training dataset and graph information, you need to correctly preprocess the dataset (e.g. feature normalization). For baseline solution in this part, you might not need to introduce extra features to reach the baseline test accuracy.\n",
        "<p>"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing"
      ],
      "execution_count": 14,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# You may change this but we suggest loading data with the following code and you may need to change\n",
        "# datatypes and do necessary data transformation after loading the raw data to the dataframe.\n",
        "dataset_paths = [\n",
        "    \"./in/test_2016_no_label.csv\",\n",
        "    \"./in/train_2016.csv\",\n",
        "    \"./in/sampleSubmission.csv\",\n",
        "    \"./in/graph.csv\",\n",
        "    \"./in/test_2012_no_label.csv\",\n",
        "    \"./in/train_2012.csv\"\n",
        "] \n",
        "\n",
        "test = pd.read_csv(dataset_paths[0], sep=',', encoding='unicode_escape', thousands=',')\n",
        "train = pd.read_csv(dataset_paths[1], sep=',', encoding='unicode_escape', thousands=',')\n",
        "\n",
        "\n",
        "# Columns that make sense to standardize\n",
        "data_range = ['MedianIncome','MigraRate','BirthRate','DeathRate','BachelorRate','UnemploymentRate']\n",
        "\n",
        "# Make sure you comment your code clearly and you may refer to these comments in the part 2.4\n",
        "# TODO\n",
        "\n",
        "    \n",
        "# Get the Labels for the training data\n",
        "yTr = (train[\"DEM\"] > train[\"GOP\"]).astype(int).values\n",
        "\n",
        "# Scaling Training,Testing Features based on training data\n",
        "scaler = preprocessing.StandardScaler()\n",
        "xTr = scaler.fit_transform(train[data_range])\n",
        "xTe = scaler.transform(test[data_range])"
      ],
      "execution_count": 15,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>2.2 Use At Least Two Training Algorithms from class:</h3><p>\n",
        "You need to use at least two training algorithms from class. You can use your code from previous projects or any packages you imported in part 1.1."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm,tree"
      ],
      "execution_count": 19,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure you comment your code clearly and you may refer to these comments in the part 2.4\n",
        "# TODO\n",
        "\n",
        "svmClf = svm.SVC()\n",
        "svmClf.fit(xTr, yTr)\n",
        "sv = svmClf.predict(xTe)\n",
        "print(sv)\n",
        "\n",
        "\n",
        "treeClf = tree.DecisionTreeClassifier()\n",
        "treeClf.fit(xTr, yTr)\n",
        "tr = treeClf.predict(xTe)\n",
        "print(tr)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "[0 0 0 ... 0 0 0]\n",
            "[0 0 0 ... 0 0 0]\n"
          ],
          "output_type": "stream"
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>2.3 Training, Validation and Model Selection:</h3><p>\n",
        "You need to split your data to a training set and validation set or performing a cross-validation for model selection."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import make_scorer"
      ],
      "execution_count": 25,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#  Test svm c parmater and kernel combinations\n",
        "#  Uses cross validation fucntion from scikit\n",
        "#  score validation using weighted_accuracy and 5 setf of kfolds\n",
        "#  take the mean score as the accuracy with those parameters.\n",
        "#  save best kernel,c combination\n",
        "\n",
        "n, = yTr.shape\n",
        "\n",
        "# Loss Function/ Accuracy function\n",
        "score = make_scorer(weighted_accuracy)"
      ],
      "execution_count": 29,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "####       SVM     #####\n",
        "\n",
        "# K-Fold\n",
        "k = 5\n",
        "\n",
        "# Model Params\n",
        "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
        "# Through trial and error we limited out linspace to test high \n",
        "# performing C parameters \n",
        "cList = np.linspace(12,18,10)\n",
        "\n",
        "# Acumulators\n",
        "best_c = None\n",
        "best_kernel = None\n",
        "acc = None\n",
        "\n",
        "#Tuning\n",
        "for kernel in kernels:\n",
        "    for c in cList :\n",
        "        svmTemp = svm.SVC(C = c, kernel = kernel)\n",
        "        curr_score = cross_val_score(svmTemp, xTr, yTr, scoring = score, cv=k).mean()\n",
        "        if (acc is None) or (acc < curr_score):\n",
        "            acc = curr_score\n",
        "            best_c = c\n",
        "            best_kernel = kernel\n",
        "print (acc, best_c, best_kernel)\n",
        "# 0.7079030910609857 16.0 rbf\n",
        "\n",
        "# Chosen SVM Model\n",
        "svmClf = svm.SVC(C = best_c, kernel = best_kernel)\n",
        "svmClf.fit(xTr,yTr)\n",
        "sv = svmClf.predict(xTe)\n",
        "# SVC(C=11.0)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "0.7079030910609857 16.0 rbf\n"
          ],
          "output_type": "stream"
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#####       DECISION TREE       #####\n",
        "\n",
        "# We care about pruning here actually so we need to add that as a tuning param we can use a range and make it large \n",
        "# max_depth and min sample split should be useful, I think max depth is what we want tho\n",
        "\n",
        "# K-Fold\n",
        "k = n//50\n",
        "\n",
        "# Model Params\n",
        "criterion = [\"gini\", \"entropy\"]\n",
        "splitter = [\"best\"]\n",
        "depthList = np.linspace(1,1000000, 400).tolist() + [None]\n",
        "\n",
        "# Accumulators\n",
        "best_cri = None\n",
        "best_spl = None\n",
        "best_depth = None\n",
        "acc = None\n",
        "\n",
        "# Tuning\n",
        "for cri in criterion:\n",
        "    for split in splitter:\n",
        "        for depth in depthList:\n",
        "            treeTemp = tree.DecisionTreeClassifier(criterion = cri, splitter = split, max_depth=depth)\n",
        "            curr_score = cross_val_score(treeTemp, xTr, yTr, scoring = score, cv=k).mean()\n",
        "            if (acc is None) or (acc < curr_score):\n",
        "                acc = curr_score\n",
        "                best_cri = cri\n",
        "                best_spl = split\n",
        "                best_depth = depth\n",
        "print (acc, best_cri, best_spl, best_depth)\n",
        "# 0.7225814536340853 gini best 70708.0\n",
        "# This does not perform as well on our dataset. The testing error isn't super accurate (2% off)\n",
        "\n",
        "# Chosen Tree Model\n",
        "treeClf = tree.DecisionTreeClassifier(criterion = best_cri, splitter = best_spl, max_depth=best_depth)\n",
        "treeClf.fit(xTr,yTr)\n",
        "tr = treeClf.predict(xTe)\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "0.7235201657557246 gini best 541353.8421052631\n"
          ],
          "output_type": "stream"
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>2.4 Explanation in Words:</h3><p>\n",
        "    You need to answer the following questions in the markdown cell after this cell:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.4.1 How did you preprocess the dataset and features?\n",
        "\n",
        "2.4.2 Which two learning methods from class did you choose and why did you made the choices?\n",
        "\n",
        "2.4.3 How did you do the model selection?\n",
        "\n",
        "2.4.4 Does the test performance reach a given baseline 68% performanc? (Please include a screenshot of Kaggle Submission)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ANSWERS\n",
        "**2.4.1:** We standardized the values of the real valued data. For instance, we didn't attempt to standardize the FIPS value because they were being used as indetifiers. We used the package standardScaler from scikit-learn and passed in the data frame of the relevant realvalued columns. We remembered to scale our testing data to the shape of of training data. This was easily faciliated by the functions from the package. We did not use the data from Dem of Gop number becuase we would not thave them for the testing data.\n",
        "\n",
        "**2.4.2:** We use an SVM and a Decision Tree. We reasoned that the data would be some what linearly seprable hence the SVM. The Decision Tree made sense becuase we had relatively few features so over fitting would not be a major issue. We knew we neaded to learn a nonlinear rule and the decision trees and a kernelized svm would be able to do this.\n",
        "\n",
        "**2.4.3:** We use scikit's functions to reason about model selection. We tuned multiple paramters looping and checking with 50-fold cross validation we tuned for the bet combinations. \n",
        "\n",
        "**2.4.4:** Yes, our models reach the 68% baseline. \n",
        "\n",
        "![basic](basic_submission.png)\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Part 3: Creative Solution</h2><p>"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>3.1 Open-ended Code:</h3><p>\n",
        "You may follow the steps in part 2 again but making innovative changes like creating new features, using new training algorithms, etc. Make sure you explain everything clearly in part 3.2. Note that reaching the 75% creative baseline is only a small portion of this part. Any creative ideas will receive most points as long as they are reasonable and clearly explained."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#### ADDITIONAL IDEAS ####\n",
        "\n",
        "# We could compile a list of all DEM and all GOP and give ratings based on that\n",
        "# We could see how the change in unemployment affects, change in birth rate (high birth rate implies younger pop)\n",
        "# Change in death rate\n",
        "# Ratio of death to birth\n",
        "# Migration also implies younger pop\n",
        "# Income is important\n",
        "# Get nearest neighbor from"
      ],
      "execution_count": 6,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "############### LOAD DATASETS ###############\n",
        "\n",
        "graph = pd.read_csv(dataset_paths[3], sep=',', encoding='unicode_escape', thousands=',')\n",
        "test_2012 = pd.read_csv(dataset_paths[4], sep=',', encoding='unicode_escape', thousands=',')\n",
        "train_2012 = pd.read_csv(dataset_paths[5], sep=',', encoding='unicode_escape', thousands=',')\n",
        "\n",
        "# A hash for the county FIPS\n",
        "counties = train[\"FIPS\"].append(test[\"FIPS\"]).to_frame().set_index(\"FIPS\")\n",
        "counties['i'] = list(range(len(counties.index)))"
      ],
      "execution_count": 34,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "################ FEATURE EXTRACTION FROM 2012 DATA ################\n",
        "\n",
        "# We plan to use changes in the datasets between 2012 and 2016 as features\n",
        "\n",
        "#### DATA ####\n",
        "data_range = ['MedianIncome','MigraRate','BirthRate','DeathRate','BachelorRate','UnemploymentRate']\n",
        "xTr_2012_delta =  train[data_range] - train_2012[data_range]\n",
        "xTe_2012_delta = test[data_range] - test_2012[data_range] \n",
        "### SCALING ###\n",
        "scaler3 = preprocessing.StandardScaler()\n",
        "xTr_2012_delta = scaler.fit_transform(xTr_2012_delta)\n",
        "xTe_2012_delta = scaler.transform(xTe_2012_delta)\n",
        "\n",
        "xTr_2012_use = np.concatenate((xTr, xTr_2012_delta), axis=1)\n",
        "xTe_2012_use = np.concatenate((xTe, xTe_2012_delta), axis=1)"
      ],
      "execution_count": 35,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "############### FEATURE EXTRACTION FROM GRAPH.CSV ##################\n",
        "\n",
        "#### PREDICTIONS SO FAR ####\n",
        "\n",
        "# Best prediction so far\n",
        "best_pred = sv\n",
        "\n",
        "# Create indexes for training and testing data\n",
        "train_i = train.set_index(\"FIPS\")\n",
        "train_i['i'] = list(range(len(train.index)))\n",
        "test_i = test.set_index(\"FIPS\")\n",
        "test_i['i'] = list(range(len(test.index)))\n",
        "\n",
        "\n",
        "## either returns the known label or our best prediction\n",
        "\"\"\"\n",
        "    A county's best known prediction\n",
        "\"\"\"\n",
        "def get_affiliation(county):\n",
        "    in_training = county in train_i.index\n",
        "\n",
        "    if in_training:\n",
        "        label = yTr[train_i.i[county]] \n",
        "    else:\n",
        "        label = best_pred[test_i.i[county]]\n",
        "\n",
        "    return -1 if label == 0 else 1"
      ],
      "execution_count": 36,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#### EXTRACTING THE LABEL INFORMATION OF NEIGHBORS ####\n",
        "\n",
        "# Accumulators\n",
        "# a list of neighbors \n",
        "counties['neighbors'] = [[] for x in range(len(counties.index))]\n",
        "# a list of neighbors labels\n",
        "counties['neighbor_labels'] = [0 for x in range(len(counties.index))]\n",
        "# the number of neighbors we have information from\n",
        "counties['confidence'] = [0 for x in range(len(counties.index))]\n",
        "\n",
        "\n",
        "# Add in the data to our three new features\n",
        "for ind in graph.index:\n",
        "    # make sure the source and the destitnation are in our counties list\n",
        "    # make sure we dont count the source as a destination to itself to avoid corrupting the data\n",
        "    if graph.SRC[ind] in counties.index and graph.DST[ind] in counties.index and graph.DST[ind] != graph.SRC[ind]:   \n",
        "        # take the pair and append the neighbor to its list of neighbors\n",
        "        # classify the neighor off of the data or our previous svm\n",
        "        # and add how many neighbors we saw to inform our model of the confidence in this information and avoid false zeros \n",
        "        if graph.SRC[ind] not in counties.neighbors[graph.DST[ind]]:\n",
        "            counties.loc[graph.DST[ind], 'neighbors'].append(graph.SRC[ind])\n",
        "            counties.loc[graph.DST[ind], 'neighbor_labels'] += get_affiliation(graph.SRC[ind])\n",
        "            counties.loc[graph.DST[ind], 'confidence'] += 1\n",
        "\n",
        "        if graph.DST[ind] not in counties.neighbors[graph.SRC[ind]]:\n",
        "            counties.loc[graph.SRC[ind], 'neighbors'].append(graph.DST[ind])\n",
        "            counties.loc[graph.SRC[ind],'neighbor_labels'] = counties.neighbor_labels[graph.SRC[ind]] + get_affiliation(graph.DST[ind])\n",
        "            counties.loc[graph.SRC[ind],'confidence'] += 1\n",
        "\n",
        "\n",
        "# I think we don't need confidence\n",
        "d_range = ['neighbor_labels', 'confidence']\n",
        "xTr_counties_id = counties.i[train['FIPS']]\n",
        "xTe_counties_id = counties.i[test['FIPS']]\n",
        "\n",
        "xTr_gr = counties[d_range].values[xTr_counties_id]\n",
        "xTe_gr = counties[d_range].values[xTe_counties_id]\n",
        "# xTr_gr = counties[d_range][train['FIPS']]\n",
        "# xTe_gr = counties[d_range][test['FIPS']]\n",
        "\n",
        "### SCALING ###\n",
        "scaler2 = preprocessing.StandardScaler()\n",
        "xTr_gr = scaler.fit_transform(xTr_gr)\n",
        "xTe_gr = scaler.transform(xTe_gr)\n",
        "\n",
        "xTr_gr_use = np.concatenate((xTr, xTr_gr), axis=1)\n",
        "xTe_gr_use = np.concatenate((xTe, xTe_gr), axis=1)\n",
        "\n",
        "xTr_cr = np.concatenate((xTr_2012_use, xTr_gr), axis=1)\n",
        "xTe_cr = np.concatenate((xTe_2012_use, xTe_gr), axis=1)"
      ],
      "execution_count": 38,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "##################### LOAD SCIPY ####################\n",
        "from scipy.sparse.csgraph import shortest_path"
      ],
      "execution_count": 39,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "##################### GET ADJACENCY/DISTANCE MATRICES #########################\n",
        "\n",
        "# Increase the index to accomodate for the counties that are not in the test data\n",
        "for ind in graph.index:\n",
        "    if graph.SRC[ind] not in counties.index:\n",
        "        counties.loc[graph.SRC[ind]] = ({'FIPS':graph.SRC[ind], 'i': len(counties.index)})\n",
        "    if graph.DST[ind] not in counties.index:\n",
        "        counties.loc[graph.DST[ind]] = ({'FIPS':graph.DST[ind], 'i': len(counties.index)})\n",
        "\n",
        "# Create the adjacency matrix\n",
        "n = len(counties.index)\n",
        "adj_matrix = np.zeros((n,n))\n",
        "\n",
        "# Construct Adjacency matrix\n",
        "for ind in graph.index:\n",
        "    adj_matrix[counties.i[graph.SRC[ind]]][counties.i[graph.DST[ind]]] = adj_matrix[counties.i[graph.DST[ind]]][counties.i[graph.SRC[ind]]] = 1\n",
        "\n",
        "# Distance matrix \n",
        "dist_mat = shortest_path(adj_matrix,directed=True,method='auto', unweighted=True)\n",
        "\n",
        "# Find the neighbors that are 1 away and 2 away\n",
        "two_away = (dist_mat<3).astype(int)\n",
        "one_away = (dist_mat<2).astype(int)\n",
        "\n",
        "# HUGE FEATURE SPACE \n",
        "xTr_adj = np.concatenate((xTr, one_away[counties.i[train[\"FIPS\"]]]), axis=1)\n",
        "xTe_adj = np.concatenate((xTe, one_away[counties.i[test[\"FIPS\"]]]), axis=1)"
      ],
      "execution_count": 40,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "############       SVM -> Adjacency #FAILED     ###########\n",
        "xTr_d = xTr_adj\n",
        "xTe_d = xTe_adj\n",
        "# K-Fold\n",
        "k = 10\n",
        "\n",
        "# Model Params\n",
        "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
        "# Through trial and error we limited out linspace to test high \n",
        "# performing C parameters \n",
        "cList = np.linspace(1,30,10)\n",
        "\n",
        "# Acumulators\n",
        "best_c = None\n",
        "best_kernel = None\n",
        "acc = None\n",
        "\n",
        "# Tuning\n",
        "for kernel in kernels:\n",
        "    for c in cList :\n",
        "        svmTemp = svm.SVC(C = c, kernel = kernel)\n",
        "        curr_score = cross_val_score(svmTemp, xTr_d, yTr, scoring = score, cv=k).mean()\n",
        "        if (acc is None) or (acc < curr_score):\n",
        "            acc = curr_score\n",
        "            best_c = c\n",
        "            best_kernel = kernel\n",
        "print (acc, best_c, best_kernel)\n",
        "# 0.7079030910609857 16.0 rbf\n",
        "\n",
        "# Chosen SVM Model\n",
        "svmClf = svm.SVC(C = 7, kernel = 'rbf')\n",
        "svmClf.fit(xTr,yTr)\n",
        "print(cross_val_score(svmClf, xTr_d, yTr, scoring = score, cv=k).mean())\n",
        "sv_adj = svmClf.predict(xTe_d)\n",
        "# SVC(C=11.0)"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "############       SVM -> Graph DATA     ###########\n",
        "xTr_d = xTr_gr_use\n",
        "xTe_d = xTe_gr_use\n",
        "# K-Fold\n",
        "k = 10\n",
        "\n",
        "# Model Params\n",
        "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
        "# Through trial and error we limited out linspace to test high \n",
        "# performing C parameters \n",
        "cList = np.linspace(1,10,13)\n",
        "\n",
        "# Acumulators\n",
        "best_c = None\n",
        "best_kernel = None\n",
        "acc = None\n",
        "\n",
        "# Tuning\n",
        "for kernel in kernels:\n",
        "    for c in cList :\n",
        "        svmTemp = svm.SVC(C = c, kernel = kernel)\n",
        "        curr_score = cross_val_score(svmTemp, xTr_d, yTr, scoring = score, cv=k).mean()\n",
        "        if (acc is None) or (acc < curr_score):\n",
        "            acc = curr_score\n",
        "            best_c = c\n",
        "            best_kernel = kernel\n",
        "print (acc, best_c, best_kernel)\n",
        "# 0.7079030910609857 16.0 rbf\n",
        "\n",
        "# Chosen SVM Model\n",
        "svmClf = svm.SVC(C = best_c, kernel = best_kernel)\n",
        "svmClf.fit(xTr_d,yTr)\n",
        "print(cross_val_score(svmClf, xTr_d, yTr, scoring = score, cv=k).mean())\n",
        "sv_gr = svmClf.predict(xTe_d)"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "0.7367195161817588 7.0 rbf\n",
            "0.7367195161817588\n"
          ],
          "output_type": "stream"
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "############       SVM -> Change in Demographics     ###########\n",
        "xTr_d = xTr_2012_use\n",
        "xTe_d = xTe_2012_use\n",
        "# K-Fold\n",
        "k = 10\n",
        "\n",
        "# Model Params\n",
        "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
        "# Through trial and error we limited out linspace to test high \n",
        "# performing C parameters \n",
        "cList = np.linspace(5,25,15)\n",
        "\n",
        "# Acumulators\n",
        "best_c = None\n",
        "best_kernel = None\n",
        "acc = None\n",
        "\n",
        "# Tuning\n",
        "for kernel in kernels:\n",
        "    for c in cList :\n",
        "        svmTemp = svm.SVC(C = c, kernel = kernel)\n",
        "        curr_score = cross_val_score(svmTemp, xTr_d, yTr, scoring = score, cv=k).mean()\n",
        "        if (acc is None) or (acc < curr_score):\n",
        "            acc = curr_score\n",
        "            best_c = c\n",
        "            best_kernel = kernel\n",
        "print (acc, best_c, best_kernel)\n",
        "# 0.7079030910609857 16.0 rbf\n",
        "\n",
        "# Chosen SVM Model\n",
        "svmClf = svm.SVC(C = best_c, kernel = best_kernel)\n",
        "svmClf.fit(xTr_d,yTr)\n",
        "print(cross_val_score(svmClf, xTr_d, yTr, scoring = score, cv=k).mean())\n",
        "sv_2012 = svmClf.predict(xTe_d)"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "0.7774436090225564 19.285714285714285 rbf\n",
            "0.7774436090225564\n"
          ],
          "output_type": "stream"
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "############       SVM -> all changes     ###########\n",
        "xTr_d = xTr_cr\n",
        "xTe_d = xTe_cr\n",
        "# K-Fold\n",
        "k = 10\n",
        "\n",
        "# Model Params\n",
        "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
        "# Through trial and error we limited out linspace to test high \n",
        "# performing C parameters \n",
        "cList = np.linspace(4,16,10)\n",
        "\n",
        "# Acumulators\n",
        "best_c = None\n",
        "best_kernel = None\n",
        "acc = None\n",
        "\n",
        "# Tuning\n",
        "for kernel in kernels:\n",
        "    for c in cList :\n",
        "        svmTemp = svm.SVC(C = c, kernel = kernel)\n",
        "        curr_score = cross_val_score(svmTemp, xTr_d, yTr, scoring = score, cv=k).mean()\n",
        "        if (acc is None) or (acc < curr_score):\n",
        "            acc = curr_score\n",
        "            best_c = c\n",
        "            best_kernel = kernel\n",
        "print (acc, best_c, best_kernel)\n",
        "# 0.7079030910609857 16.0 rbf\n",
        "\n",
        "# Chosen SVM Model\n",
        "svmClf = svm.SVC(C = best_c, kernel = best_kernel)\n",
        "svmClf.fit(xTr_d,yTr)\n",
        "print(cross_val_score(svmClf, xTr_d, yTr, scoring = score, cv=k).mean())\n",
        "sv_all = svmClf.predict(xTe_d)"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "0.7766917293233083 13.333333333333332 rbf\n",
            "0.7766917293233083\n"
          ],
          "output_type": "stream"
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#####       DECISION TREE ->  #Really LONG Training time      #####\n",
        "\n",
        "xTr_d = xTr_adj\n",
        "xTe_d = xTe_adj\n",
        "\n",
        "# We care about pruning here actually so we need to add that as a tuning param we can use a range and make it large \n",
        "# max_depth and min sample split should be useful, I think max depth is what we want tho\n",
        "\n",
        "# K-Fold\n",
        "k = n//50\n",
        "\n",
        "# Model Params\n",
        "criterion = [\"gini\"]\n",
        "splitter = [\"best\"]\n",
        "depthList = [541353.8421052631] + [None]\n",
        "\n",
        "# Accumulators\n",
        "best_cri = None\n",
        "best_spl = None\n",
        "best_depth = None\n",
        "acc = None\n",
        "\n",
        "# Tuning\n",
        "for cri in criterion:\n",
        "    for split in splitter:\n",
        "        for depth in depthList:\n",
        "            treeTemp = tree.DecisionTreeClassifier(criterion = cri, splitter = split, max_depth=depth)\n",
        "            curr_score = cross_val_score(treeTemp, xTr_d, yTr, scoring = score, cv=k).mean()\n",
        "            if (acc is None) or (acc < curr_score):\n",
        "                acc = curr_score\n",
        "                best_cri = cri\n",
        "                best_spl = split\n",
        "                best_depth = depth\n",
        "print (acc, best_cri, best_spl, best_depth)\n",
        "# 0.7225814536340853 gini best 70708.0\n",
        "# This does not perform as well on our dataset. The testing error isn't super accurate (2% off)\n",
        "\n",
        "# Chosen Tree Model\n",
        "treeClf = tree.DecisionTreeClassifier(criterion = best_cri, splitter = best_spl, max_depth=best_depth)\n",
        "treeClf.fit(xTr_d,yTr)\n",
        "tr_cr = treeClf.predict(xTe_d)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "0.7409598214285713 gini best 541353.8421052631\n"
          ],
          "output_type": "stream"
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "##### NEURAL NETWORK #####\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "#### INPUT FORMATS\n",
        "# xTr_adj -> adjacency list\n",
        "# xTr_2012_use -> 2012 change + xTr\n",
        "# xTr_gr_use -> graph + xTr\n",
        "# xTr_cr -> graph + 2012 change + xTr "
      ],
      "execution_count": 160,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "####      MLP NN -> all data   #####\n",
        "xTr_d = xTr_cr\n",
        "xTe_d = xTe_cr\n",
        "k = 5\n",
        "\n",
        "\n",
        "# We are not sure how exactly to tue the shape of the neural network\n",
        "# We are using a random assortment of layer shapes and testing on that\n",
        "hidden_layer_shapes = [(100,), (50,20),(100, 70, 50, 20), (200, 100, 50)]\n",
        "activation_funcs = ['identity', 'logistic', 'tanh', 'relu']\n",
        "solvers = ['lbfgs', 'adam']\n",
        "\n",
        "# Accumulators\n",
        "best_act = None\n",
        "best_solver = None\n",
        "best_shape = None \n",
        "acc = None\n",
        "\n",
        "for solver in solvers:\n",
        "    for act_func in activation_funcs:\n",
        "        for shape in hidden_layer_shapes:\n",
        "            nnTemp = MLPClassifier(max_iter = 400, activation= act_func, hidden_layer_sizes=shape, solver = solver, random_state=1)\n",
        "            curr_score = cross_val_score(nnTemp, xTr_d, yTr, scoring = score, cv=k).mean()\n",
        "            if (acc is None) or (acc < curr_score):\n",
        "                    acc = curr_score\n",
        "                    best_act = act_func\n",
        "                    best_solver = solver\n",
        "                    best_shape = shape\n",
        "\n",
        "\n",
        "nnClf = MLPClassifier(max_iter = 400, activation= best_act, hidden_layer_sizes=best_shape, solver = best_solver, random_state=1)\n",
        "nnClf.fit(xTr_d,yTr)\n",
        "nn_cr = nnClf.predict(xTe_d)\n",
        "\n",
        "print(best_act)\n",
        "print(best_solver)\n",
        "print(best_shape)\n",
        "print(cross_val_score(nnClf, xTr_d, yTr, scoring = score, cv=k).mean())"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "0.8052046783625733\n"
          ],
          "output_type": "stream"
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>3.2 Explanation in Words:</h3><p>"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "You need to answer the following questions in a markdown cell after this cell:\n",
        "\n",
        "3.2.1 How much did you manage to improve performance on the test set compared to part 2? Did you reach the 75% accuracy for the test in Kaggle? (Please include a screenshot of Kaggle Submission)\n",
        "\n",
        "3.2.2 Please explain in detail how you achieved this and what you did specifically and why you tried this."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ANSWERS\n",
        "**3.2.1:** We managed to increase our accuracy by roughly 10 percent! We met the 75% accuracy rating\n",
        "\n",
        "![creative](creative_submission.png)\n",
        "\n",
        "**3.2.2:** Intially we tried creating an adjacency matrix from the graph and passing that into an SVM as a feature. This caused a massive increase in the feature space. This did not improve our accuracy. Then we re-formulated the graph data more intelligently. We used the known labels of the neighbors as well as our best predictions of the unknown neighbors to create new features for each county. Additionally we computed the diffrences in the given six features from 2012 until 2016.\n",
        "\n",
        "## Feature Spaces\n",
        "The list of creative feature combinations are as follows:\n",
        "\\begin{table}[h!]\n",
        "\\centering\n",
        "\\begin{tabular}{|| c | c ||} \n",
        " \\hline\n",
        " \\textbf{Feature} & \\textbf{Contents}  \\\\ [0.5ex] \n",
        " \\hline\\hline\n",
        " \\textbf{xTr\\_adj} & adjacency list  \\\\ \n",
        " \\hline\n",
        " \\textbf{xTr\\_2012\\_use} & 2012 change + xTr  \\\\ \n",
        " \\hline\n",
        " \\textbf{xTr\\_gr\\_use} & graph + xTr   \\\\ \n",
        " \\hline\n",
        " \\textbf{xTr\\_cr} & graph + 2012 change + xTr  \\\\ \n",
        " \\hline\n",
        "\\end{tabular}\n",
        "\\end{table}\n",
        "\n",
        "\n",
        "\n",
        "### Adjacency List\n",
        "The rational behind getting graph data in the form of an adjacency list was that we believed that neihboring counties tend to vote alike (clustering) as can be seen in the graph provided. We thought that knowing what counties were next to each other regardless of its affilition would be a great indicator. We also tried creating a **distance matrix** and finding neighbors that were two away. The pitfall of this method was that it clogged up the feature space. we went from 6 -> ~3110 features. It was hard to train on and did not significantly raise the accuracy of our model when run on an SVM and Decision Tree.\n",
        "\n",
        "![colored_graph](colored_graph.png)\n",
        "\n",
        "### Graph\n",
        "This refers to the sum of known labels for the immediate neighbors of each county (we used prior svm predictions ~70% accuracy on the test data and true labels on the training data). The thought process behind this was similar to the adjacency matrix but by compiling what we knew into one feature, we both improved the accuracy and training time of our models compared to the adjacency list.<br>\n",
        "**Important consideration**\n",
        "- We made republican counties count as a (-1) and Dems count as a (+1). WE believe there is more to be learned from *5* republican neighbors than from *2*. The same goes for democrats. This is a stylistic choice that we believe provides our models with more information that simply the majority label. \n",
        "- We noticed that some counties appear in the graph that we know nothing about, these counties count as *0* as they do not improve our confidence at all.\n",
        "- We also added a confidence variable. This variable distigushed between no knowledge situations. For instance we may have a zero in the case where we know nothing about our neighbors but this is not the same as the casee where we have seen two neighboring dem and rep counties. Intuitively, where there is no-knowledge about our neighbors our model may may skew toward a particular classification, however when the decision splits 50-50 and results in a zero this may skew in the other direction. Additionally the 5-4 case and 3-2 case both result in ones but the were arrived at by diffrent means. Therefore, we provide the number of neighbors (standardized) we have informtion about as a feature to our models.\n",
        "\n",
        "### 2012 Change\n",
        "The change in our original features from 2012 -> 2016:\n",
        "These are our hypothese on the data. Look at the initial comments at section **3.1**\n",
        "\n",
        "### xTr\n",
        "Our original feature space\n",
        "\n",
        "## Results\n",
        " Our two best models with these new feature were an svm trained and validated on ***xTr_gr*** and a neural network trained on ***xTr_cr***. These models were able to meet the bench mark handly. For both of the models we did extensive validation and parameter tuning."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Part 4: Kaggle Submission</h2><p>\n",
        "You need to generate a prediction CSV using the following cell from your trained model and submit the direct output of your code to Kaggle. The CSV shall contain TWO column named exactly \"FIPS\" and \"Result\" and 1555 total rows excluding the column names, \"FIPS\" column shall contain FIPS of counties with same order as in the test_2016_no_label.csv while \"Result\" column shall contain the 0 or 1 prdicaitons for corresponding columns. A sample predication file can be downloaded from Kaggle."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO\n",
        "\n",
        "# You may use pandas to generate a dataframe with FIPS and your predictions first \n",
        "# and then use to_csv to generate a CSV file.\n",
        "\n",
        "out = pd.read_csv(dataset_paths[2], sep=',', encoding='unicode_escape', thousands=',')\n",
        "out['FIPS'] = test['FIPS']\n",
        "out['Result'] = sv\n",
        "out.to_csv(\"./out/svmOut.csv\", index=False)\n",
        "out['Result'] = tr\n",
        "out.to_csv(\"./out/treeOut.csv\", index=False)\n",
        "out['Result'] = sv_adj\n",
        "out.to_csv(\"./out/svmAdjCreativeOut.csv\", index=False)\n",
        "out['Result'] = sv_all\n",
        "out.to_csv(\"./out/svmAllCreativeOut.csv\", index=False)\n",
        "out['Result'] = sv_gr\n",
        "out.to_csv(\"./out/svmGraphCreativeOut.csv\", index=False)\n",
        "out['Result'] = sv_2012\n",
        "out.to_csv(\"./out/svm2012CreativeOut.csv\", index=False)\n",
        "out['Result'] = nn_cr\n",
        "out.to_csv(\"./out/nnAllCreativeOut.csv\", index=False)"
      ],
      "execution_count": 184,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Part 5: Resources and Literature Used</h2><p>"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "https://scikit-learn.org/stable/index.html#\n",
        "\n",
        "CS 4780/5780 Introduction to Machine Learning (2020FA) lectures and slides\n",
        "\n",
        "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html\n",
        "\n",
        "https://stackoverflow.com/questions/10628262/inserting-image-into-ipython-notebook-markdown\n",
        "\n",
        "https://stackoverflow.com/questions/15998491/how-to-convert-ipython-notebooks-to-pdf-and-html/25942111\n",
        "\n",
        "https://datalore.jetbrains.com\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [],
      "metadata": {}
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 0
}